{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Horse Or Human CNN -- Training\n",
    "\n",
    "This notebook is used to construct and train the Horse or Human CNN model.\n",
    "\n",
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\nFound 925 images belonging to 2 classes.\nFound 102 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Apply scaling and augmentations (zooms, rotate, flip, etc.) to training set \n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, validation_split=0.1)\n",
    "training_set = train_datagen.flow_from_directory('horse-or-human/train', target_size=(64, 64), batch_size=32, class_mode='binary', subset='training')\n",
    "validation_set = train_datagen.flow_from_directory('horse-or-human/train', target_size=(64, 64), batch_size=32, class_mode='binary', subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN\n",
    "\n",
    "Note that `input_shape` is `[64, 64, 3]` because the images are 64x64px and have RGB (3 pixel) values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the cnn\n",
    "cnn = tf.keras.models.Sequential()\n",
    "# Add first convolutional layer with max pooling\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.20))\n",
    "# Add second convolutional layer with max pooling\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.20))\n",
    "# Add third convolutional layer with max pooling\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.20))\n",
    "# Add fourth convolutional layer with max pooling\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Dropout(0.20))\n",
    "# Add flattening layer\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "# Add full connection layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "# Add output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 29 steps, validate for 4 steps\nEpoch 1/4\n29/29 [==============================] - 6s 208ms/step - loss: 0.6839 - accuracy: 0.5665 - val_loss: 0.6587 - val_accuracy: 0.8627\nEpoch 2/4\n29/29 [==============================] - 5s 168ms/step - loss: 0.5052 - accuracy: 0.7589 - val_loss: 0.3086 - val_accuracy: 0.8922\nEpoch 3/4\n29/29 [==============================] - 5s 168ms/step - loss: 0.2908 - accuracy: 0.8865 - val_loss: 0.1825 - val_accuracy: 0.9412\nEpoch 4/4\n29/29 [==============================] - 5s 169ms/step - loss: 0.2116 - accuracy: 0.9070 - val_loss: 0.0901 - val_accuracy: 0.9706\n"
    }
   ],
   "source": [
    "# Compile the CNN\n",
    "cnn.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the CNN\n",
    "history = cnn.fit(x=training_set, validation_data=validation_set, epochs=4)\n",
    "# Save model in current directory\n",
    "with open('NewModel.json', 'w') as json_file:\n",
    "    json_file.write(cnn.to_json())\n",
    "# Save weights in current directory\n",
    "cnn.save_weights('NewModel.hdf5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n29/29 [==============================] - 4s 147ms/step - loss: 0.1328 - accuracy: 0.9568\nTraining accuracy:  [0.1327894127060627, 0.9567568]\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\n4/4 [==============================] - 0s 118ms/step - loss: 0.1039 - accuracy: 0.9706\nValidation accuracy:  [0.10391198098659515, 0.9705882]\n"
    }
   ],
   "source": [
    "train_accuracy = cnn.evaluate(training_set)\n",
    "print(\"Training accuracy: \", train_accuracy)\n",
    "validation_accuracy = cnn.evaluate(validation_set)\n",
    "print(\"Validation accuracy: \", validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbasecondae5992da88ac746559c628f2e757124b5",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}